// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: googleapis/google/assistant/embedded/v1alpha1/embedded_assistant.proto
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Assistant.Embedded.V1Alpha1 {

  /// <summary>Holder for reflection information generated from googleapis/google/assistant/embedded/v1alpha1/embedded_assistant.proto</summary>
  public static partial class EmbeddedAssistantReflection {

    #region Descriptor
    /// <summary>File descriptor for googleapis/google/assistant/embedded/v1alpha1/embedded_assistant.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static EmbeddedAssistantReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "CkZnb29nbGVhcGlzL2dvb2dsZS9hc3Npc3RhbnQvZW1iZWRkZWQvdjFhbHBo",
            "YTEvZW1iZWRkZWRfYXNzaXN0YW50LnByb3RvEiJnb29nbGUuYXNzaXN0YW50",
            "LmVtYmVkZGVkLnYxYWxwaGExGhxnb29nbGUvYXBpL2Fubm90YXRpb25zLnBy",
            "b3RvGhdnb29nbGUvcnBjL3N0YXR1cy5wcm90byL1AQoOQ29udmVyc2VDb25m",
            "aWcSSgoPYXVkaW9faW5fY29uZmlnGAEgASgLMjEuZ29vZ2xlLmFzc2lzdGFu",
            "dC5lbWJlZGRlZC52MWFscGhhMS5BdWRpb0luQ29uZmlnEkwKEGF1ZGlvX291",
            "dF9jb25maWcYAiABKAsyMi5nb29nbGUuYXNzaXN0YW50LmVtYmVkZGVkLnYx",
            "YWxwaGExLkF1ZGlvT3V0Q29uZmlnEkkKDmNvbnZlcnNlX3N0YXRlGAMgASgL",
            "MjEuZ29vZ2xlLmFzc2lzdGFudC5lbWJlZGRlZC52MWFscGhhMS5Db252ZXJz",
            "ZVN0YXRlIrYBCg1BdWRpb0luQ29uZmlnEkwKCGVuY29kaW5nGAEgASgOMjou",
            "Z29vZ2xlLmFzc2lzdGFudC5lbWJlZGRlZC52MWFscGhhMS5BdWRpb0luQ29u",
            "ZmlnLkVuY29kaW5nEhkKEXNhbXBsZV9yYXRlX2hlcnR6GAIgASgFIjwKCEVu",
            "Y29kaW5nEhgKFEVOQ09ESU5HX1VOU1BFQ0lGSUVEEAASDAoITElORUFSMTYQ",
            "ARIICgRGTEFDEAIi4wEKDkF1ZGlvT3V0Q29uZmlnEk0KCGVuY29kaW5nGAEg",
            "ASgOMjsuZ29vZ2xlLmFzc2lzdGFudC5lbWJlZGRlZC52MWFscGhhMS5BdWRp",
            "b091dENvbmZpZy5FbmNvZGluZxIZChFzYW1wbGVfcmF0ZV9oZXJ0ehgCIAEo",
            "BRIZChF2b2x1bWVfcGVyY2VudGFnZRgDIAEoBSJMCghFbmNvZGluZxIYChRF",
            "TkNPRElOR19VTlNQRUNJRklFRBAAEgwKCExJTkVBUjE2EAESBwoDTVAzEAIS",
            "DwoLT1BVU19JTl9PR0cQAyIrCg1Db252ZXJzZVN0YXRlEhoKEmNvbnZlcnNh",
            "dGlvbl9zdGF0ZRgBIAEoDCIeCghBdWRpb091dBISCgphdWRpb19kYXRhGAEg",
            "ASgMIr0CCg5Db252ZXJzZVJlc3VsdBIbChNzcG9rZW5fcmVxdWVzdF90ZXh0",
            "GAEgASgJEhwKFHNwb2tlbl9yZXNwb25zZV90ZXh0GAIgASgJEhoKEmNvbnZl",
            "cnNhdGlvbl9zdGF0ZRgDIAEoDBJaCg9taWNyb3Bob25lX21vZGUYBCABKA4y",
            "QS5nb29nbGUuYXNzaXN0YW50LmVtYmVkZGVkLnYxYWxwaGExLkNvbnZlcnNl",
            "UmVzdWx0Lk1pY3JvcGhvbmVNb2RlEhkKEXZvbHVtZV9wZXJjZW50YWdlGAUg",
            "ASgFIl0KDk1pY3JvcGhvbmVNb2RlEh8KG01JQ1JPUEhPTkVfTU9ERV9VTlNQ",
            "RUNJRklFRBAAEhQKEENMT1NFX01JQ1JPUEhPTkUQARIUChBESUFMT0dfRk9M",
            "TE9XX09OEAIifwoPQ29udmVyc2VSZXF1ZXN0EkQKBmNvbmZpZxgBIAEoCzIy",
            "Lmdvb2dsZS5hc3Npc3RhbnQuZW1iZWRkZWQudjFhbHBoYTEuQ29udmVyc2VD",
            "b25maWdIABISCghhdWRpb19pbhgCIAEoDEgAQhIKEGNvbnZlcnNlX3JlcXVl",
            "c3Qi6gIKEENvbnZlcnNlUmVzcG9uc2USIwoFZXJyb3IYASABKAsyEi5nb29n",
            "bGUucnBjLlN0YXR1c0gAElQKCmV2ZW50X3R5cGUYAiABKA4yPi5nb29nbGUu",
            "YXNzaXN0YW50LmVtYmVkZGVkLnYxYWxwaGExLkNvbnZlcnNlUmVzcG9uc2Uu",
            "RXZlbnRUeXBlSAASQQoJYXVkaW9fb3V0GAMgASgLMiwuZ29vZ2xlLmFzc2lz",
            "dGFudC5lbWJlZGRlZC52MWFscGhhMS5BdWRpb091dEgAEkQKBnJlc3VsdBgF",
            "IAEoCzIyLmdvb2dsZS5hc3Npc3RhbnQuZW1iZWRkZWQudjFhbHBoYTEuQ29u",
            "dmVyc2VSZXN1bHRIACI9CglFdmVudFR5cGUSGgoWRVZFTlRfVFlQRV9VTlNQ",
            "RUNJRklFRBAAEhQKEEVORF9PRl9VVFRFUkFOQ0UQAUITChFjb252ZXJzZV9y",
            "ZXNwb25zZTKOAQoRRW1iZWRkZWRBc3Npc3RhbnQSeQoIQ29udmVyc2USMy5n",
            "b29nbGUuYXNzaXN0YW50LmVtYmVkZGVkLnYxYWxwaGExLkNvbnZlcnNlUmVx",
            "dWVzdBo0Lmdvb2dsZS5hc3Npc3RhbnQuZW1iZWRkZWQudjFhbHBoYTEuQ29u",
            "dmVyc2VSZXNwb25zZSgBMAFChgEKJmNvbS5nb29nbGUuYXNzaXN0YW50LmVt",
            "YmVkZGVkLnYxYWxwaGExQg5Bc3Npc3RhbnRQcm90b1ABWkpnb29nbGUuZ29s",
            "YW5nLm9yZy9nZW5wcm90by9nb29nbGVhcGlzL2Fzc2lzdGFudC9lbWJlZGRl",
            "ZC92MWFscGhhMTtlbWJlZGRlZGIGcHJvdG8z"));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.AnnotationsReflection.Descriptor, global::Google.Rpc.StatusReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseConfig), global::Google.Assistant.Embedded.V1Alpha1.ConverseConfig.Parser, new[]{ "AudioInConfig", "AudioOutConfig", "ConverseState" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig), global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig.Parser, new[]{ "Encoding", "SampleRateHertz" }, null, new[]{ typeof(global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig.Types.Encoding) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig), global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig.Parser, new[]{ "Encoding", "SampleRateHertz", "VolumePercentage" }, null, new[]{ typeof(global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig.Types.Encoding) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseState), global::Google.Assistant.Embedded.V1Alpha1.ConverseState.Parser, new[]{ "ConversationState" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.AudioOut), global::Google.Assistant.Embedded.V1Alpha1.AudioOut.Parser, new[]{ "AudioData" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseResult), global::Google.Assistant.Embedded.V1Alpha1.ConverseResult.Parser, new[]{ "SpokenRequestText", "SpokenResponseText", "ConversationState", "MicrophoneMode", "VolumePercentage" }, null, new[]{ typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseResult.Types.MicrophoneMode) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseRequest), global::Google.Assistant.Embedded.V1Alpha1.ConverseRequest.Parser, new[]{ "Config", "AudioIn" }, new[]{ "ConverseRequest" }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseResponse), global::Google.Assistant.Embedded.V1Alpha1.ConverseResponse.Parser, new[]{ "Error", "EventType", "AudioOut", "Result" }, new[]{ "ConverseResponse" }, new[]{ typeof(global::Google.Assistant.Embedded.V1Alpha1.ConverseResponse.Types.EventType) }, null)
          }));
    }
    #endregion

  }
  #region Messages
  /// <summary>
  /// Specifies how to process the `ConverseRequest` messages.
  /// </summary>
  public sealed partial class ConverseConfig : pb::IMessage<ConverseConfig> {
    private static readonly pb::MessageParser<ConverseConfig> _parser = new pb::MessageParser<ConverseConfig>(() => new ConverseConfig());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConverseConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseConfig(ConverseConfig other) : this() {
      AudioInConfig = other.audioInConfig_ != null ? other.AudioInConfig.Clone() : null;
      AudioOutConfig = other.audioOutConfig_ != null ? other.AudioOutConfig.Clone() : null;
      ConverseState = other.converseState_ != null ? other.ConverseState.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseConfig Clone() {
      return new ConverseConfig(this);
    }

    /// <summary>Field number for the "audio_in_config" field.</summary>
    public const int AudioInConfigFieldNumber = 1;
    private global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig audioInConfig_;
    /// <summary>
    /// *Required* Specifies how to process the subsequent incoming audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig AudioInConfig {
      get { return audioInConfig_; }
      set {
        audioInConfig_ = value;
      }
    }

    /// <summary>Field number for the "audio_out_config" field.</summary>
    public const int AudioOutConfigFieldNumber = 2;
    private global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig audioOutConfig_;
    /// <summary>
    /// *Required* Specifies how to format the audio that will be returned.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig AudioOutConfig {
      get { return audioOutConfig_; }
      set {
        audioOutConfig_ = value;
      }
    }

    /// <summary>Field number for the "converse_state" field.</summary>
    public const int ConverseStateFieldNumber = 3;
    private global::Google.Assistant.Embedded.V1Alpha1.ConverseState converseState_;
    /// <summary>
    /// *Required* Represents the current dialog state.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.ConverseState ConverseState {
      get { return converseState_; }
      set {
        converseState_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConverseConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConverseConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(AudioInConfig, other.AudioInConfig)) return false;
      if (!object.Equals(AudioOutConfig, other.AudioOutConfig)) return false;
      if (!object.Equals(ConverseState, other.ConverseState)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (audioInConfig_ != null) hash ^= AudioInConfig.GetHashCode();
      if (audioOutConfig_ != null) hash ^= AudioOutConfig.GetHashCode();
      if (converseState_ != null) hash ^= ConverseState.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (audioInConfig_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(AudioInConfig);
      }
      if (audioOutConfig_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(AudioOutConfig);
      }
      if (converseState_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(ConverseState);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (audioInConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(AudioInConfig);
      }
      if (audioOutConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(AudioOutConfig);
      }
      if (converseState_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(ConverseState);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConverseConfig other) {
      if (other == null) {
        return;
      }
      if (other.audioInConfig_ != null) {
        if (audioInConfig_ == null) {
          audioInConfig_ = new global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig();
        }
        AudioInConfig.MergeFrom(other.AudioInConfig);
      }
      if (other.audioOutConfig_ != null) {
        if (audioOutConfig_ == null) {
          audioOutConfig_ = new global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig();
        }
        AudioOutConfig.MergeFrom(other.AudioOutConfig);
      }
      if (other.converseState_ != null) {
        if (converseState_ == null) {
          converseState_ = new global::Google.Assistant.Embedded.V1Alpha1.ConverseState();
        }
        ConverseState.MergeFrom(other.ConverseState);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (audioInConfig_ == null) {
              audioInConfig_ = new global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig();
            }
            input.ReadMessage(audioInConfig_);
            break;
          }
          case 18: {
            if (audioOutConfig_ == null) {
              audioOutConfig_ = new global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig();
            }
            input.ReadMessage(audioOutConfig_);
            break;
          }
          case 26: {
            if (converseState_ == null) {
              converseState_ = new global::Google.Assistant.Embedded.V1Alpha1.ConverseState();
            }
            input.ReadMessage(converseState_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Specifies how to process the `audio_in` data that will be provided in
  /// subsequent requests. For recommended settings, see the Google Assistant SDK
  /// [best practices](https://developers.google.com/assistant/best-practices).
  /// </summary>
  public sealed partial class AudioInConfig : pb::IMessage<AudioInConfig> {
    private static readonly pb::MessageParser<AudioInConfig> _parser = new pb::MessageParser<AudioInConfig>(() => new AudioInConfig());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<AudioInConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioInConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioInConfig(AudioInConfig other) : this() {
      encoding_ = other.encoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioInConfig Clone() {
      return new AudioInConfig(this);
    }

    /// <summary>Field number for the "encoding" field.</summary>
    public const int EncodingFieldNumber = 1;
    private global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig.Types.Encoding encoding_ = 0;
    /// <summary>
    /// *Required* Encoding of audio data sent in all `audio_in` messages.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig.Types.Encoding Encoding {
      get { return encoding_; }
      set {
        encoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// *Required* Sample rate (in Hertz) of the audio data sent in all `audio_in`
    /// messages. Valid values are from 16000-24000, but 16000 is optimal.
    /// For best results, set the sampling rate of the audio source to 16000 Hz.
    /// If that's not possible, use the native sample rate of the audio source
    /// (instead of re-sampling).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as AudioInConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(AudioInConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Encoding != other.Encoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Encoding != 0) hash ^= Encoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (Encoding != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Encoding != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(AudioInConfig other) {
      if (other == null) {
        return;
      }
      if (other.Encoding != 0) {
        Encoding = other.Encoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            encoding_ = (global::Google.Assistant.Embedded.V1Alpha1.AudioInConfig.Types.Encoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the AudioInConfig message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Audio encoding of the data sent in the audio message.
      /// Audio must be one-channel (mono). The only language supported is "en-US".
      /// </summary>
      public enum Encoding {
        /// <summary>
        /// Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][].
        /// </summary>
        [pbr::OriginalName("ENCODING_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
        /// This encoding includes no header, only the raw audio bytes.
        /// </summary>
        [pbr::OriginalName("LINEAR16")] Linear16 = 1,
        /// <summary>
        /// [`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
        /// Codec) is the recommended encoding because it is
        /// lossless--therefore recognition is not compromised--and
        /// requires only about half the bandwidth of `LINEAR16`. This encoding
        /// includes the `FLAC` stream header followed by audio data. It supports
        /// 16-bit and 24-bit samples, however, not all fields in `STREAMINFO` are
        /// supported.
        /// </summary>
        [pbr::OriginalName("FLAC")] Flac = 2,
      }

    }
    #endregion

  }

  /// <summary>
  /// Specifies the desired format for the server to use when it returns
  /// `audio_out` messages.
  /// </summary>
  public sealed partial class AudioOutConfig : pb::IMessage<AudioOutConfig> {
    private static readonly pb::MessageParser<AudioOutConfig> _parser = new pb::MessageParser<AudioOutConfig>(() => new AudioOutConfig());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<AudioOutConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioOutConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioOutConfig(AudioOutConfig other) : this() {
      encoding_ = other.encoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      volumePercentage_ = other.volumePercentage_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioOutConfig Clone() {
      return new AudioOutConfig(this);
    }

    /// <summary>Field number for the "encoding" field.</summary>
    public const int EncodingFieldNumber = 1;
    private global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig.Types.Encoding encoding_ = 0;
    /// <summary>
    /// *Required* The encoding of audio data to be returned in all `audio_out`
    /// messages.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig.Types.Encoding Encoding {
      get { return encoding_; }
      set {
        encoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// *Required* The sample rate in Hertz of the audio data returned in
    /// `audio_out` messages. Valid values are: 16000-24000.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "volume_percentage" field.</summary>
    public const int VolumePercentageFieldNumber = 3;
    private int volumePercentage_;
    /// <summary>
    /// *Required* Current volume setting of the device's audio output.
    /// Valid values are 1 to 100 (corresponding to 1% to 100%).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int VolumePercentage {
      get { return volumePercentage_; }
      set {
        volumePercentage_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as AudioOutConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(AudioOutConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Encoding != other.Encoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (VolumePercentage != other.VolumePercentage) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Encoding != 0) hash ^= Encoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (VolumePercentage != 0) hash ^= VolumePercentage.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (Encoding != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (VolumePercentage != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(VolumePercentage);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Encoding != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) Encoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (VolumePercentage != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(VolumePercentage);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(AudioOutConfig other) {
      if (other == null) {
        return;
      }
      if (other.Encoding != 0) {
        Encoding = other.Encoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.VolumePercentage != 0) {
        VolumePercentage = other.VolumePercentage;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            encoding_ = (global::Google.Assistant.Embedded.V1Alpha1.AudioOutConfig.Types.Encoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 24: {
            VolumePercentage = input.ReadInt32();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the AudioOutConfig message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Audio encoding of the data returned in the audio message. All encodings are
      /// raw audio bytes with no header, except as indicated below.
      /// </summary>
      public enum Encoding {
        /// <summary>
        /// Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][].
        /// </summary>
        [pbr::OriginalName("ENCODING_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
        /// </summary>
        [pbr::OriginalName("LINEAR16")] Linear16 = 1,
        /// <summary>
        /// MP3 audio encoding. The sample rate is encoded in the payload.
        /// </summary>
        [pbr::OriginalName("MP3")] Mp3 = 2,
        /// <summary>
        /// Opus-encoded audio wrapped in an ogg container. The result will be a
        /// file which can be played natively on Android and in some browsers (such
        /// as Chrome). The quality of the encoding is considerably higher than MP3
        /// while using the same bitrate. The sample rate is encoded in the payload.
        /// </summary>
        [pbr::OriginalName("OPUS_IN_OGG")] OpusInOgg = 3,
      }

    }
    #endregion

  }

  /// <summary>
  /// Provides information about the current dialog state.
  /// </summary>
  public sealed partial class ConverseState : pb::IMessage<ConverseState> {
    private static readonly pb::MessageParser<ConverseState> _parser = new pb::MessageParser<ConverseState>(() => new ConverseState());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConverseState> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseState() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseState(ConverseState other) : this() {
      conversationState_ = other.conversationState_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseState Clone() {
      return new ConverseState(this);
    }

    /// <summary>Field number for the "conversation_state" field.</summary>
    public const int ConversationStateFieldNumber = 1;
    private pb::ByteString conversationState_ = pb::ByteString.Empty;
    /// <summary>
    /// *Required* The `conversation_state` value returned in the prior
    /// `ConverseResponse`. Omit (do not set the field) if there was no prior
    /// `ConverseResponse`. If there was a prior `ConverseResponse`, do not omit
    /// this field; doing so will end that conversation (and this new request will
    /// start a new conversation).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString ConversationState {
      get { return conversationState_; }
      set {
        conversationState_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConverseState);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConverseState other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (ConversationState != other.ConversationState) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (ConversationState.Length != 0) hash ^= ConversationState.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (ConversationState.Length != 0) {
        output.WriteRawTag(10);
        output.WriteBytes(ConversationState);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (ConversationState.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(ConversationState);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConverseState other) {
      if (other == null) {
        return;
      }
      if (other.ConversationState.Length != 0) {
        ConversationState = other.ConversationState;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            ConversationState = input.ReadBytes();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// The audio containing the assistant's response to the query. Sequential chunks
  /// of audio data are received in sequential `ConverseResponse` messages.
  /// </summary>
  public sealed partial class AudioOut : pb::IMessage<AudioOut> {
    private static readonly pb::MessageParser<AudioOut> _parser = new pb::MessageParser<AudioOut>(() => new AudioOut());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<AudioOut> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioOut() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioOut(AudioOut other) : this() {
      audioData_ = other.audioData_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioOut Clone() {
      return new AudioOut(this);
    }

    /// <summary>Field number for the "audio_data" field.</summary>
    public const int AudioDataFieldNumber = 1;
    private pb::ByteString audioData_ = pb::ByteString.Empty;
    /// <summary>
    /// *Output-only* The audio data containing the assistant's response to the
    /// query. Sequential chunks of audio data are received in sequential
    /// `ConverseResponse` messages.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString AudioData {
      get { return audioData_; }
      set {
        audioData_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as AudioOut);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(AudioOut other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (AudioData != other.AudioData) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (AudioData.Length != 0) hash ^= AudioData.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (AudioData.Length != 0) {
        output.WriteRawTag(10);
        output.WriteBytes(AudioData);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (AudioData.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(AudioData);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(AudioOut other) {
      if (other == null) {
        return;
      }
      if (other.AudioData.Length != 0) {
        AudioData = other.AudioData;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            AudioData = input.ReadBytes();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// The semantic result for the user's spoken query.
  /// </summary>
  public sealed partial class ConverseResult : pb::IMessage<ConverseResult> {
    private static readonly pb::MessageParser<ConverseResult> _parser = new pb::MessageParser<ConverseResult>(() => new ConverseResult());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConverseResult> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResult() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResult(ConverseResult other) : this() {
      spokenRequestText_ = other.spokenRequestText_;
      spokenResponseText_ = other.spokenResponseText_;
      conversationState_ = other.conversationState_;
      microphoneMode_ = other.microphoneMode_;
      volumePercentage_ = other.volumePercentage_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResult Clone() {
      return new ConverseResult(this);
    }

    /// <summary>Field number for the "spoken_request_text" field.</summary>
    public const int SpokenRequestTextFieldNumber = 1;
    private string spokenRequestText_ = "";
    /// <summary>
    /// *Output-only* The recognized transcript of what the user said.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string SpokenRequestText {
      get { return spokenRequestText_; }
      set {
        spokenRequestText_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "spoken_response_text" field.</summary>
    public const int SpokenResponseTextFieldNumber = 2;
    private string spokenResponseText_ = "";
    /// <summary>
    /// *Output-only* The text of the assistant's spoken response. This is only
    /// returned for an IFTTT action.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string SpokenResponseText {
      get { return spokenResponseText_; }
      set {
        spokenResponseText_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "conversation_state" field.</summary>
    public const int ConversationStateFieldNumber = 3;
    private pb::ByteString conversationState_ = pb::ByteString.Empty;
    /// <summary>
    /// *Output-only* State information for subsequent `ConverseRequest`. This
    /// value should be saved in the client and returned in the
    /// `conversation_state` with the next `ConverseRequest`. (The client does not
    /// need to interpret or otherwise use this value.) There is no need to save
    /// this information across device restarts.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString ConversationState {
      get { return conversationState_; }
      set {
        conversationState_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "microphone_mode" field.</summary>
    public const int MicrophoneModeFieldNumber = 4;
    private global::Google.Assistant.Embedded.V1Alpha1.ConverseResult.Types.MicrophoneMode microphoneMode_ = 0;
    /// <summary>
    /// *Output-only* Specifies the mode of the microphone after this `Converse`
    /// RPC is processed.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.ConverseResult.Types.MicrophoneMode MicrophoneMode {
      get { return microphoneMode_; }
      set {
        microphoneMode_ = value;
      }
    }

    /// <summary>Field number for the "volume_percentage" field.</summary>
    public const int VolumePercentageFieldNumber = 5;
    private int volumePercentage_;
    /// <summary>
    /// *Output-only* Updated volume level. The value will be 0 or omitted
    /// (indicating no change) unless a voice command such as "Increase the volume"
    /// or "Set volume level 4" was recognized, in which case the value will be
    /// between 1 and 100 (corresponding to the new volume level of 1% to 100%).
    /// Typically, a client should use this volume level when playing the
    /// `audio_out` data, and retain this value as the current volume level and
    /// supply it in the `AudioOutConfig` of the next `ConverseRequest`. (Some
    /// clients may also implement other ways to allow the current volume level to
    /// be changed, for example, by providing a knob that the user can turn.)
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int VolumePercentage {
      get { return volumePercentage_; }
      set {
        volumePercentage_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConverseResult);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConverseResult other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (SpokenRequestText != other.SpokenRequestText) return false;
      if (SpokenResponseText != other.SpokenResponseText) return false;
      if (ConversationState != other.ConversationState) return false;
      if (MicrophoneMode != other.MicrophoneMode) return false;
      if (VolumePercentage != other.VolumePercentage) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (SpokenRequestText.Length != 0) hash ^= SpokenRequestText.GetHashCode();
      if (SpokenResponseText.Length != 0) hash ^= SpokenResponseText.GetHashCode();
      if (ConversationState.Length != 0) hash ^= ConversationState.GetHashCode();
      if (MicrophoneMode != 0) hash ^= MicrophoneMode.GetHashCode();
      if (VolumePercentage != 0) hash ^= VolumePercentage.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (SpokenRequestText.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(SpokenRequestText);
      }
      if (SpokenResponseText.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(SpokenResponseText);
      }
      if (ConversationState.Length != 0) {
        output.WriteRawTag(26);
        output.WriteBytes(ConversationState);
      }
      if (MicrophoneMode != 0) {
        output.WriteRawTag(32);
        output.WriteEnum((int) MicrophoneMode);
      }
      if (VolumePercentage != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(VolumePercentage);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (SpokenRequestText.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(SpokenRequestText);
      }
      if (SpokenResponseText.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(SpokenResponseText);
      }
      if (ConversationState.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(ConversationState);
      }
      if (MicrophoneMode != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) MicrophoneMode);
      }
      if (VolumePercentage != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(VolumePercentage);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConverseResult other) {
      if (other == null) {
        return;
      }
      if (other.SpokenRequestText.Length != 0) {
        SpokenRequestText = other.SpokenRequestText;
      }
      if (other.SpokenResponseText.Length != 0) {
        SpokenResponseText = other.SpokenResponseText;
      }
      if (other.ConversationState.Length != 0) {
        ConversationState = other.ConversationState;
      }
      if (other.MicrophoneMode != 0) {
        MicrophoneMode = other.MicrophoneMode;
      }
      if (other.VolumePercentage != 0) {
        VolumePercentage = other.VolumePercentage;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            SpokenRequestText = input.ReadString();
            break;
          }
          case 18: {
            SpokenResponseText = input.ReadString();
            break;
          }
          case 26: {
            ConversationState = input.ReadBytes();
            break;
          }
          case 32: {
            microphoneMode_ = (global::Google.Assistant.Embedded.V1Alpha1.ConverseResult.Types.MicrophoneMode) input.ReadEnum();
            break;
          }
          case 40: {
            VolumePercentage = input.ReadInt32();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the ConverseResult message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Possible states of the microphone after a `Converse` RPC completes.
      /// </summary>
      public enum MicrophoneMode {
        /// <summary>
        /// No mode specified.
        /// </summary>
        [pbr::OriginalName("MICROPHONE_MODE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// The service is not expecting a follow-on question from the user.
        /// The microphone should remain off until the user re-activates it.
        /// </summary>
        [pbr::OriginalName("CLOSE_MICROPHONE")] CloseMicrophone = 1,
        /// <summary>
        /// The service is expecting a follow-on question from the user. The
        /// microphone should be re-opened when the `AudioOut` playback completes
        /// (by starting a new `Converse` RPC call to send the new audio).
        /// </summary>
        [pbr::OriginalName("DIALOG_FOLLOW_ON")] DialogFollowOn = 2,
      }

    }
    #endregion

  }

  /// <summary>
  /// The top-level message sent by the client. Clients must send at least two, and
  /// typically numerous `ConverseRequest` messages. The first message must
  /// contain a `config` message and must not contain `audio_in` data. All
  /// subsequent messages must contain `audio_in` data and must not contain a
  /// `config` message.
  /// </summary>
  public sealed partial class ConverseRequest : pb::IMessage<ConverseRequest> {
    private static readonly pb::MessageParser<ConverseRequest> _parser = new pb::MessageParser<ConverseRequest>(() => new ConverseRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConverseRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseRequest(ConverseRequest other) : this() {
      switch (other.ConverseRequestCase) {
        case ConverseRequestOneofCase.Config:
          Config = other.Config.Clone();
          break;
        case ConverseRequestOneofCase.AudioIn:
          AudioIn = other.AudioIn;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseRequest Clone() {
      return new ConverseRequest(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    /// <summary>
    /// The `config` message provides information to the recognizer that
    /// specifies how to process the request.
    /// The first `ConverseRequest` message must contain a `config` message.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.ConverseConfig Config {
      get { return converseRequestCase_ == ConverseRequestOneofCase.Config ? (global::Google.Assistant.Embedded.V1Alpha1.ConverseConfig) converseRequest_ : null; }
      set {
        converseRequest_ = value;
        converseRequestCase_ = value == null ? ConverseRequestOneofCase.None : ConverseRequestOneofCase.Config;
      }
    }

    /// <summary>Field number for the "audio_in" field.</summary>
    public const int AudioInFieldNumber = 2;
    /// <summary>
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `ConverseRequest` messages. The first `ConverseRequest`
    /// message must not contain `audio_in` data and all subsequent
    /// `ConverseRequest` messages must contain `audio_in` data. The audio bytes
    /// must be encoded as specified in `AudioInConfig`.
    /// Audio must be sent at approximately real-time (16000 samples per second).
    /// An error will be returned if audio is sent significantly faster or
    /// slower.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString AudioIn {
      get { return converseRequestCase_ == ConverseRequestOneofCase.AudioIn ? (pb::ByteString) converseRequest_ : pb::ByteString.Empty; }
      set {
        converseRequest_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        converseRequestCase_ = ConverseRequestOneofCase.AudioIn;
      }
    }

    private object converseRequest_;
    /// <summary>Enum of possible cases for the "converse_request" oneof.</summary>
    public enum ConverseRequestOneofCase {
      None = 0,
      Config = 1,
      AudioIn = 2,
    }
    private ConverseRequestOneofCase converseRequestCase_ = ConverseRequestOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseRequestOneofCase ConverseRequestCase {
      get { return converseRequestCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearConverseRequest() {
      converseRequestCase_ = ConverseRequestOneofCase.None;
      converseRequest_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConverseRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConverseRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (AudioIn != other.AudioIn) return false;
      if (ConverseRequestCase != other.ConverseRequestCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (converseRequestCase_ == ConverseRequestOneofCase.Config) hash ^= Config.GetHashCode();
      if (converseRequestCase_ == ConverseRequestOneofCase.AudioIn) hash ^= AudioIn.GetHashCode();
      hash ^= (int) converseRequestCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (converseRequestCase_ == ConverseRequestOneofCase.Config) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (converseRequestCase_ == ConverseRequestOneofCase.AudioIn) {
        output.WriteRawTag(18);
        output.WriteBytes(AudioIn);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (converseRequestCase_ == ConverseRequestOneofCase.Config) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (converseRequestCase_ == ConverseRequestOneofCase.AudioIn) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(AudioIn);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConverseRequest other) {
      if (other == null) {
        return;
      }
      switch (other.ConverseRequestCase) {
        case ConverseRequestOneofCase.Config:
          Config = other.Config;
          break;
        case ConverseRequestOneofCase.AudioIn:
          AudioIn = other.AudioIn;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            global::Google.Assistant.Embedded.V1Alpha1.ConverseConfig subBuilder = new global::Google.Assistant.Embedded.V1Alpha1.ConverseConfig();
            if (converseRequestCase_ == ConverseRequestOneofCase.Config) {
              subBuilder.MergeFrom(Config);
            }
            input.ReadMessage(subBuilder);
            Config = subBuilder;
            break;
          }
          case 18: {
            AudioIn = input.ReadBytes();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// The top-level message received by the client. A series of one or more
  /// `ConverseResponse` messages are streamed back to the client.
  /// </summary>
  public sealed partial class ConverseResponse : pb::IMessage<ConverseResponse> {
    private static readonly pb::MessageParser<ConverseResponse> _parser = new pb::MessageParser<ConverseResponse>(() => new ConverseResponse());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConverseResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Assistant.Embedded.V1Alpha1.EmbeddedAssistantReflection.Descriptor.MessageTypes[7]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResponse(ConverseResponse other) : this() {
      switch (other.ConverseResponseCase) {
        case ConverseResponseOneofCase.Error:
          Error = other.Error.Clone();
          break;
        case ConverseResponseOneofCase.EventType:
          EventType = other.EventType;
          break;
        case ConverseResponseOneofCase.AudioOut:
          AudioOut = other.AudioOut.Clone();
          break;
        case ConverseResponseOneofCase.Result:
          Result = other.Result.Clone();
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResponse Clone() {
      return new ConverseResponse(this);
    }

    /// <summary>Field number for the "error" field.</summary>
    public const int ErrorFieldNumber = 1;
    /// <summary>
    /// *Output-only* If set, returns a [google.rpc.Status][google.rpc.Status] message that
    /// specifies the error for the operation.
    /// If an error occurs during processing, this message will be set and there
    /// will be no further messages sent.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Rpc.Status Error {
      get { return converseResponseCase_ == ConverseResponseOneofCase.Error ? (global::Google.Rpc.Status) converseResponse_ : null; }
      set {
        converseResponse_ = value;
        converseResponseCase_ = value == null ? ConverseResponseOneofCase.None : ConverseResponseOneofCase.Error;
      }
    }

    /// <summary>Field number for the "event_type" field.</summary>
    public const int EventTypeFieldNumber = 2;
    /// <summary>
    /// *Output-only* Indicates the type of event.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.ConverseResponse.Types.EventType EventType {
      get { return converseResponseCase_ == ConverseResponseOneofCase.EventType ? (global::Google.Assistant.Embedded.V1Alpha1.ConverseResponse.Types.EventType) converseResponse_ : 0; }
      set {
        converseResponse_ = value;
        converseResponseCase_ = ConverseResponseOneofCase.EventType;
      }
    }

    /// <summary>Field number for the "audio_out" field.</summary>
    public const int AudioOutFieldNumber = 3;
    /// <summary>
    /// *Output-only* The audio containing the assistant's response to the query.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.AudioOut AudioOut {
      get { return converseResponseCase_ == ConverseResponseOneofCase.AudioOut ? (global::Google.Assistant.Embedded.V1Alpha1.AudioOut) converseResponse_ : null; }
      set {
        converseResponse_ = value;
        converseResponseCase_ = value == null ? ConverseResponseOneofCase.None : ConverseResponseOneofCase.AudioOut;
      }
    }

    /// <summary>Field number for the "result" field.</summary>
    public const int ResultFieldNumber = 5;
    /// <summary>
    /// *Output-only* The semantic result for the user's spoken query.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Assistant.Embedded.V1Alpha1.ConverseResult Result {
      get { return converseResponseCase_ == ConverseResponseOneofCase.Result ? (global::Google.Assistant.Embedded.V1Alpha1.ConverseResult) converseResponse_ : null; }
      set {
        converseResponse_ = value;
        converseResponseCase_ = value == null ? ConverseResponseOneofCase.None : ConverseResponseOneofCase.Result;
      }
    }

    private object converseResponse_;
    /// <summary>Enum of possible cases for the "converse_response" oneof.</summary>
    public enum ConverseResponseOneofCase {
      None = 0,
      Error = 1,
      EventType = 2,
      AudioOut = 3,
      Result = 5,
    }
    private ConverseResponseOneofCase converseResponseCase_ = ConverseResponseOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConverseResponseOneofCase ConverseResponseCase {
      get { return converseResponseCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearConverseResponse() {
      converseResponseCase_ = ConverseResponseOneofCase.None;
      converseResponse_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConverseResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConverseResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Error, other.Error)) return false;
      if (EventType != other.EventType) return false;
      if (!object.Equals(AudioOut, other.AudioOut)) return false;
      if (!object.Equals(Result, other.Result)) return false;
      if (ConverseResponseCase != other.ConverseResponseCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (converseResponseCase_ == ConverseResponseOneofCase.Error) hash ^= Error.GetHashCode();
      if (converseResponseCase_ == ConverseResponseOneofCase.EventType) hash ^= EventType.GetHashCode();
      if (converseResponseCase_ == ConverseResponseOneofCase.AudioOut) hash ^= AudioOut.GetHashCode();
      if (converseResponseCase_ == ConverseResponseOneofCase.Result) hash ^= Result.GetHashCode();
      hash ^= (int) converseResponseCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (converseResponseCase_ == ConverseResponseOneofCase.Error) {
        output.WriteRawTag(10);
        output.WriteMessage(Error);
      }
      if (converseResponseCase_ == ConverseResponseOneofCase.EventType) {
        output.WriteRawTag(16);
        output.WriteEnum((int) EventType);
      }
      if (converseResponseCase_ == ConverseResponseOneofCase.AudioOut) {
        output.WriteRawTag(26);
        output.WriteMessage(AudioOut);
      }
      if (converseResponseCase_ == ConverseResponseOneofCase.Result) {
        output.WriteRawTag(42);
        output.WriteMessage(Result);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (converseResponseCase_ == ConverseResponseOneofCase.Error) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Error);
      }
      if (converseResponseCase_ == ConverseResponseOneofCase.EventType) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) EventType);
      }
      if (converseResponseCase_ == ConverseResponseOneofCase.AudioOut) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(AudioOut);
      }
      if (converseResponseCase_ == ConverseResponseOneofCase.Result) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Result);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConverseResponse other) {
      if (other == null) {
        return;
      }
      switch (other.ConverseResponseCase) {
        case ConverseResponseOneofCase.Error:
          Error = other.Error;
          break;
        case ConverseResponseOneofCase.EventType:
          EventType = other.EventType;
          break;
        case ConverseResponseOneofCase.AudioOut:
          AudioOut = other.AudioOut;
          break;
        case ConverseResponseOneofCase.Result:
          Result = other.Result;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            global::Google.Rpc.Status subBuilder = new global::Google.Rpc.Status();
            if (converseResponseCase_ == ConverseResponseOneofCase.Error) {
              subBuilder.MergeFrom(Error);
            }
            input.ReadMessage(subBuilder);
            Error = subBuilder;
            break;
          }
          case 16: {
            converseResponse_ = input.ReadEnum();
            converseResponseCase_ = ConverseResponseOneofCase.EventType;
            break;
          }
          case 26: {
            global::Google.Assistant.Embedded.V1Alpha1.AudioOut subBuilder = new global::Google.Assistant.Embedded.V1Alpha1.AudioOut();
            if (converseResponseCase_ == ConverseResponseOneofCase.AudioOut) {
              subBuilder.MergeFrom(AudioOut);
            }
            input.ReadMessage(subBuilder);
            AudioOut = subBuilder;
            break;
          }
          case 42: {
            global::Google.Assistant.Embedded.V1Alpha1.ConverseResult subBuilder = new global::Google.Assistant.Embedded.V1Alpha1.ConverseResult();
            if (converseResponseCase_ == ConverseResponseOneofCase.Result) {
              subBuilder.MergeFrom(Result);
            }
            input.ReadMessage(subBuilder);
            Result = subBuilder;
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the ConverseResponse message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Indicates the type of event.
      /// </summary>
      public enum EventType {
        /// <summary>
        /// No event specified.
        /// </summary>
        [pbr::OriginalName("EVENT_TYPE_UNSPECIFIED")] Unspecified = 0,
        /// <summary>
        /// This event indicates that the server has detected the end of the user's
        /// speech utterance and expects no additional speech. Therefore, the server
        /// will not process additional audio (although it may subsequently return
        /// additional results). The client should stop sending additional audio
        /// data, half-close the gRPC connection, and wait for any additional results
        /// until the server closes the gRPC connection.
        /// </summary>
        [pbr::OriginalName("END_OF_UTTERANCE")] EndOfUtterance = 1,
      }

    }
    #endregion

  }

  #endregion

}

#endregion Designer generated code
